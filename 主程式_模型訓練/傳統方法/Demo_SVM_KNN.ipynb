{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "s5KOYoITctVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e854ac1-24ea-466d-f861-a13320fa3188"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = \"/content/drive/MyDrive/fNIRS_Deeplearning_Test\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)\n"
      ],
      "metadata": {
        "id": "EgX1GnXmd2NV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e698adb-bdc9-44a4-d174-f12396c4e7ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['30subjects-20220706T144134Z-001.zip',\n",
              " 'dataset',\n",
              " 'wandb',\n",
              " 'model_run_exis_sweep.ipynb',\n",
              " 'model_run_exis_sweep_20220903.ipynb',\n",
              " 'src_before20230324',\n",
              " 'Untitled0.ipynb',\n",
              " 'src_before20230417',\n",
              " 'model_run_exis_sweep_20230417.ipynb',\n",
              " 'project.csv',\n",
              " 'src_before20230509',\n",
              " 'model_run_exis_sweep_20230323.ipynb',\n",
              " 'model_run_exis_sweep_20230509.ipynb',\n",
              " 'other_model__20230509.ipynb',\n",
              " 'Untitled1.ipynb',\n",
              " 'src_before20231225',\n",
              " 'src',\n",
              " 'Demo.ipynb',\n",
              " 'vistualization (1).ipynb',\n",
              " 'finish_time.txt',\n",
              " 'download_wandb_sweep.ipynb',\n",
              " 'Demo_2.ipynb',\n",
              " 'Demo_SVM_KNN.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "path_to_this_work = '/content/drive/MyDrive/fNIRS_Deeplearning_Test'\n",
        "path_to_src = path_to_this_work + '/src'\n",
        "\n",
        "sys.path.insert(0, path_to_src)\n",
        "os.environ['PYTHONPATH'] += (\":\"+path_to_src)\n",
        "from BCI_model_class import SCCNet, SCCNet_25s, ShallowConvNet, ShallowConvNet2, cus_EEGNet\n",
        "import Dataset_training_schema as dts\n",
        "import train_model as tm"
      ],
      "metadata": {
        "id": "iVH_f3K-kSWa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "pvjyTB7t5Z50"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "Dqcv_Zfm5toC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd6edb4-c0dc-4f00-db62-a121d6b90ede"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.41)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.39.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "-e2aIluN5cXv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key=\"550fa288f18a4938b6519ecd67d11309cfd9d51e\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz4trEQZ5WFM",
        "outputId": "837d6666-b85c-4609-833c-a4367b42d3ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def average_pooling_by_interval(matrix, m):\n",
        "  # 輸入 要進行處理的矩陣matrix 以及 要抽取的特徵點數量\n",
        "  # matrix --> fNIRS 資料， (channel * time point)\n",
        "  # m --> 以時間區段作為區分，一個channel要抽取 m 特徵點\n",
        "  # 輸出\n",
        "  # 處理後的資料 (channel * m)\n",
        "  # 進行特徵抽取之後的資料，輸出的維度為\n",
        "\n",
        "  n_samples, n_channels, time_points = matrix.shape\n",
        "\n",
        "  # 區間理論大小\n",
        "  interval_size = time_points / m\n",
        "\n",
        "  # 初始化結果矩陣\n",
        "  pooled_matrix = np.zeros((n_samples, n_channels, m))\n",
        "\n",
        "  # 對每個樣本進行處理\n",
        "  for i in range(n_samples):\n",
        "      start = 0\n",
        "      for j in range(m):\n",
        "\n",
        "          # 計算裡親間終點\n",
        "          end = start + interval_size\n",
        "\n",
        "          # 擷取區間\n",
        "          reshaped_matrix = matrix[i][:, round(start):round(end)].reshape(n_channels, -1)\n",
        "          averaged_value = np.mean(reshaped_matrix, axis=1)\n",
        "          pooled_matrix[i][:, j] = averaged_value\n",
        "\n",
        "          # 更新區間起始\n",
        "          start = end\n",
        "\n",
        "  return pooled_matrix"
      ],
      "metadata": {
        "id": "9F1sAu1gVtGB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "def runClassify(method_model, data, label, testData=0, testLabel=0):\n",
        "\n",
        "\n",
        "  # if method==\"SVM\":\n",
        "  #   # 創建 SVM 的模型，使用線性函數\n",
        "  #   method_model = SVC(C=1, kernel='linear', probability=True)\n",
        "\n",
        "  # elif method == \"KNN\":\n",
        "  #   # 創建KNN分類器\n",
        "  #   method_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "\n",
        "  # 一對一的多類別分類\n",
        "  model = OneVsOneClassifier(method_model)\n",
        "\n",
        "\n",
        "\n",
        "  if isinstance(testData, int) and testData == 0 :\n",
        "  # SD\n",
        "\n",
        "    predictions = []  # 預測結果\n",
        "    true_labels = []  # 真實標籤\n",
        "\n",
        "    # Leave-One-Out CV\n",
        "    loo = LeaveOneOut()\n",
        "\n",
        "    # 依序進行 Leave-One-Out 驗證\n",
        "    for train_index, test_index in loo.split(data):\n",
        "        # 分割训练集和测试集\n",
        "        X_train, X_test = data[train_index], data[test_index]\n",
        "        y_train, y_test = label[train_index], label[test_index]\n",
        "\n",
        "        # 數據標準化\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # 模型訓練\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # 預測\n",
        "        prediction = model.predict(X_test)\n",
        "        # print(X_test.shape)\n",
        "\n",
        "        predictions.append(prediction[0]) # 預測結果\n",
        "        true_labels.append(y_test[0]) # 真實結果\n",
        "\n",
        "    # 分類精準度\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "  else:\n",
        "  # SI\n",
        "\n",
        "    # 數據標準化\n",
        "    scaler = StandardScaler()\n",
        "    train_data = scaler.fit_transform(data)\n",
        "    test_data = scaler.fit_transform(testData)\n",
        "\n",
        "    #模型訓練\n",
        "    model.fit(train_data, label)\n",
        "    prediction = model.predict(test_data)\n",
        "\n",
        "    # 分類精準度\n",
        "    accuracy = accuracy_score(testLabel, prediction)\n",
        "\n",
        "  return accuracy*100\n"
      ],
      "metadata": {
        "id": "tVG5VigsfGQS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extrat(fnirs_data, total_ch_feature_point, filter_ch_feature_point):\n",
        "\n",
        "\n",
        "  feature_HbO = average_pooling_by_interval(fnirs_data.HbO,total_ch_feature_point)\n",
        "  feature_HbR = average_pooling_by_interval(fnirs_data.HbR,total_ch_feature_point)\n",
        "  my_feature = np.concatenate((feature_HbO[:,np.newaxis,:,:], feature_HbR[:,np.newaxis,:,:]), axis=1)\n",
        "\n",
        "  sample_num = my_feature.shape[0]\n",
        "  d = my_feature.shape[1]*my_feature.shape[2]\n",
        "  data = my_feature[:,:,:,0:filter_ch_feature_point].reshape(sample_num, d*filter_ch_feature_point)\n",
        "  label = np.argmax(fnirs_data.labels, axis=1)\n",
        "  return data, label"
      ],
      "metadata": {
        "id": "-ZzAt8UNk4Ag"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(dataset,duration,total_ch_feature_point,ch_feature_num,sub,scheme,method):\n",
        "# def main():\n",
        "\n",
        "  # wandb.init()\n",
        "  # # Config is a variable that holds and saves hyperparameters and inputs\n",
        "  # config = wandb.config\n",
        "  # total_ch_feature_point=5\n",
        "  # ch_feature_num = 3\n",
        "  # dataset = config.dataset\n",
        "  # duration = config.duration\n",
        "  # sub = int(config.sub)\n",
        "  # scheme = config.scheme\n",
        "  # method = config.method\n",
        "\n",
        "  if (int(sub)>30 and dataset=='preprocess') or (int(sub)>29 and dataset in ['MI','MA']):\n",
        "    return 0\n",
        "\n",
        "  if method==\"SVM\":\n",
        "    # 創建 SVM 的模型，使用線性函數\n",
        "    method_model = SVC(C=1, kernel='linear', probability=True)\n",
        "\n",
        "  elif method == \"KNN\":\n",
        "    # 創建KNN分類器\n",
        "    method_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "  path_dataset='./dataset/'+ dataset + '_' + duration + '/'\n",
        "  s1=path_dataset+'S'\n",
        "  s2='.mat'\n",
        "  sub_range = 31 if dataset=='preprocess' else 30\n",
        "\n",
        "  if scheme==\"SI\":\n",
        "\n",
        "    # 檔案讀取\n",
        "    test, train = dts.leave_subject_out(s1,s2, data_range=range(1,sub_range), test_id=int(sub))\n",
        "\n",
        "    # 特徵提取\n",
        "    train_data, train_label = feature_extrat(train, total_ch_feature_point=total_ch_feature_point, filter_ch_feature_point=ch_feature_num)\n",
        "    test_data, test_label = feature_extrat(test, total_ch_feature_point=total_ch_feature_point, filter_ch_feature_point=ch_feature_num)\n",
        "\n",
        "\n",
        "    acc =  runClassify(method_model, train_data, train_label, testData=test_data, testLabel=test_label)\n",
        "\n",
        "\n",
        "    # wandb.log({\"Accuracy\": acc})\n",
        "    # wandb.finish()\n",
        "\n",
        "    print('ACC: ',acc)\n",
        "    return 0\n",
        "\n",
        "\n",
        "\n",
        "  elif scheme==\"SD\":\n",
        "\n",
        "    # 檔案讀取\n",
        "    data = dts.read_one_file(s1,s2,sub)\n",
        "\n",
        "    # 特徵提取\n",
        "    data, label = feature_extrat(data, total_ch_feature_point=5, filter_ch_feature_point=ch_feature_num)\n",
        "\n",
        "    acc = runClassify(method_model,data,label)\n",
        "\n",
        "\n",
        "    # wandb.log({\"Accuracy\": acc})\n",
        "    # wandb.finish()\n",
        "    print('ACC: ',acc)\n",
        "    return 0\n"
      ],
      "metadata": {
        "id": "XWcQEX9_n8Y4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "projectName = 'SVM_KNN_eval'\n",
        "sweepID = 'zfhhdori'\n",
        "sweep_agent = 'cphnycu/' + projectName + '/' + sweepID\n",
        "wandb.agent(sweep_agent, main)"
      ],
      "metadata": {
        "id": "B9azrdzXv-Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'preprocess'\n",
        "duration = '25s'\n",
        "ch_feature_num = 3\n",
        "sub = 1\n",
        "scheme = \"SD\"\n",
        "method = \"KNN\""
      ],
      "metadata": {
        "id": "REZLo4gTKHpi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(dataset = 'MA',duration = '25s',total_ch_feature_point=5, ch_feature_num = 3,sub = 1,scheme = \"SI\",method = \"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_f40AhJqHCK",
        "outputId": "b72ba6f2-6643-48bd-9578-3451450c43a1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "leave subject out\n",
            "train id:2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, test id:  1\n",
            "training data dimension:  (1680, 36, 251)\n",
            "training label dimension:  (1680, 2)\n",
            "testing data dimension:  (60, 36, 251)\n",
            "testing label dimension:  (60, 2)\n",
            "ACC:  76.66666666666667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N5K48qjGaZkh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}